# ========================================
# EditGuard fine-tuning on COCO2017
# ========================================
name: editguard_finetune_coco
model_type: IBSN
scale: 1
gpu_ids: [0]

datasets:
  train:
    name: COCO_train
    dataroot_gt: /mnt/ssd/BG/EditGuard/COCO/COCO2017/train
    dataroot_txt: /mnt/ssd/BG/EditGuard/COCO/COCO2017/train.txt
    use_shuffle: true
    n_workers: 12
    batch_size: 8

  val:
    name: COCO_val
    dataroot_gt: /mnt/ssd/BG/EditGuard/COCO/COCO2017/val
    dataroot_txt: /mnt/ssd/BG/EditGuard/COCO/COCO2017/val.txt
    n_workers: 4
    batch_size: 4

network_G:
  which_model_G: IBSN
  subnet_type: INV
  in_nc: 3
  out_nc: 3
  scale: 1

path:
  pretrain_model_G: /mnt/ssd/BG/EditGuard/EditGuard/experiments/pretrained/editguard_pretrain.pth
  strict_load: true
  resume_state: ~

train:
  optim_G:
    type: adam
    lr: 1e-4
    weight_decay: 0
    betas: [0.9, 0.999]
  lr_scheme: MultiStepLR
  lr_steps: [100000, 200000, 300000]
  lr_gamma: 0.5
  niter: 400000
  val_freq: 5000
  print_freq: 1000
  save_checkpoint_freq: 10000

  # perceptual + pixel loss
  pixel_criterion: mse
  perceptual_weight: 1.0
  lpips_weight: 0.8
  vgg_weight: 0.2
